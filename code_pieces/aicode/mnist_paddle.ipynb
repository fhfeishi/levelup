{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3db859-9071-46d1-8537-b0993a34865a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d899e32-e05d-483b-ab6a-bd76f46e9335",
   "metadata": {},
   "source": [
    "为了避免额外的学习成本，Paddle的一些api跟PyTorch很相似，Paddle的中文教程也很清楚，易于上手。现在我们直接用Paddle搭建一个LeNet来进行手写数字识别的实践。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff43b80-290c-443b-bca3-7dc3f1ad9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ce9cb-dd15-433f-87ab-55103b6de28a",
   "metadata": {},
   "source": [
    "Paddle也内置了一些数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c399b-3a0b-42bb-96ff-7f2a704eecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd071b3-edb7-4dc7-b010-f2fbe7a14ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \"import paddle; print(paddle.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cf376-37dc-404f-9ad6-139bb0e29012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \"import paddle; print(paddle.utils.run_check())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b858c21-5221-47aa-a8f5-a3261fa757e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "print(\"计算机视觉（CV）相关数据集：\", paddle.vision.datasets.__all__)\n",
    "print(\"自然语言处理（NLP）相关数据集：\", paddle.text.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69125100-27fa-4b16-8525-dda1d83378ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from paddle.vision.transforms import Normalize\n",
    "# 定义图像归一化处理方法，这里的CHW指图像格式需为 [C通道数，H图像高度，W图像宽度]\n",
    "transform = Normalize(mean=[0.5], std=[0.5], data_format=\"CHW\")\n",
    "\n",
    "# (下载)数据集并初始化 DataSet, 我们已经下载过了 \"./datasets_/mnist_dataset\"  \"MNIST/raw/x x x x\"\n",
    "data_dir = r\"./datasets_/mnist_dataset/MNIST/raw\"\n",
    "data_dir = os.path.normpath(os.path.join(os.getcwd(), data_dir))\n",
    "test_img = os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\")\n",
    "test_label = os.path.join(data_dir, \"t10k-labels-idx1-ubyte.gz\")\n",
    "train_img = os.path.join(data_dir, \"train-images-idx3-ubyte.gz\")\n",
    "train_label = os.path.join(data_dir, \"train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "train_dataset = paddle.vision.datasets.MNIST(image_path=train_img, label_path=train_label,mode=\"train\", download=False,transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(image_path=test_img, label_path=test_label,mode=\"test\", download=False,transform=transform)\n",
    "print(\n",
    "    \"train images: \", len(train_dataset), \", test images: \", len(test_dataset),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5e686-7fb3-4ab7-9707-8831ec675e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d2065-4fdc-4fbb-b299-9a14990af7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        x_data = data[0]  # 图像数据\n",
    "        y_data = data[1]  # 标签数据\n",
    "        # print(f'Batch {batch_id}: x_data shape: {x_data.shape}, y_data: {y_data}')\n",
    "        # # normal label: 0 1 2 ..\n",
    "        # 可能是解析二进制文件有问题？会有一些奇怪的标签值\n",
    "        if (y_data < 0).any() or (y_data > 9).any():\n",
    "            print(f'Invalid labels detected in batch {batch_id}: {y_data}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70e1f7-935d-4509-81e9-449c6729117a",
   "metadata": {},
   "source": [
    "num_workers：同步/异步读取数据，通过 num_workers 来设置加载数据的子进程个数，num_workers的值设为大于0时，即开启多进程方式异步加载数据，可提升数据读取速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df272d-48be-4dd1-84f8-b3c7bdc98b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'训练数据集大小: {len(train_loader.dataset)}')\n",
    "print(f'测试数据集大小: {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd749f-9133-4345-8d25-01360f6e10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看训练数据集的一个样本的维度\n",
    "print(f'一个训练图像的维度: {train_dataset[0][0].shape}')  # 图像的维度是 [1, 28, 28]\n",
    "# print(f'一个训练图像的ndarray: {train_dataset[0][0]}')  # [...]\n",
    "print(f'一个标签的类别: {train_dataset[0][-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf102-0d92-4e85-823b-404aef8d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for data in train_dataset:\n",
    "    # train_dataset[0]\n",
    "    image, label = data\n",
    "    print(\"shape of image: \", image.shape)\n",
    "    plt.title(str(label))\n",
    "    # plt.imshow(image[0])  # 原图\n",
    "    plt.imshow(image[0].squeeze(), cmap='gray')  # 灰度图，输入模型\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d708b2-9daf-4afb-aa50-c23800384d06",
   "metadata": {},
   "source": [
    "接下来我们用Paddle构建LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392a00c-f415-47a2-bb28-8d06afac5946",
   "metadata": {},
   "source": [
    "使用 paddle.nn.Sequential 构建模型，构建顺序的线性网络结构时，可以选择该方式，只需要按模型的结构顺序，一层一层加到 paddle.nn.Sequential 子类中即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade5384-8d38-41cb-8e6e-a25d2c317106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle import nn\n",
    "\n",
    "# 使用 paddle.nn.Sequential 构建 LeNet 模型\n",
    "lenet_Sequential = nn.Sequential(\n",
    "    nn.Conv2D(1, 6, 3, stride=1, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2D(2, 2),\n",
    "    nn.Conv2D(6, 16, 5, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2D(2, 2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(400, 120),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Linear(84, 10),\n",
    ")\n",
    "# 可视化模型组网结构和参数\n",
    "paddle.summary(lenet_Sequential, (1, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f51867-f98c-4b8d-ac95-2f8fb3e7c2ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lenet_Sequential.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605a148-8c6b-4492-8734-0682278919d4",
   "metadata": {},
   "source": [
    "使用 paddle.nn.Layer 构建模型。构建一些比较复杂的网络结构时，可以选择该方式，组网包括三个步骤：\n",
    "\n",
    "1. 创建一个继承自 paddle.nn.Layer 的类；\n",
    "\n",
    "2. 在类的构造函数 __init__ 中定义组网用到的神经网络层（layer）；\n",
    "\n",
    "3. 在类的前向计算函数 forward 中使用定义好的 layer 执行前向计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69067d-f860-4ad9-9455-e36c7acb2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Subclass 方式构建 LeNet 模型\n",
    "class LeNet(nn.Layer):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # 构建 features 子网，用于对输入图像进行特征提取\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2D(1, 6, 3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(2, 2),\n",
    "            nn.Conv2D(6, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(2, 2),\n",
    "        )\n",
    "        # 构建 linear 子网，用于分类\n",
    "        if num_classes > 0:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(400, 120),\n",
    "                nn.Linear(120, 84),\n",
    "                nn.Linear(84, num_classes),\n",
    "            )\n",
    "\n",
    "    # 执行前向计算\n",
    "    def forward(self, inputs):\n",
    "        x = self.features(inputs)\n",
    "\n",
    "        if self.num_classes > 0:\n",
    "            x = paddle.flatten(x, 1)\n",
    "            x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "lenet_SubClass = LeNet()\n",
    "\n",
    "# 可视化模型组网结构和参数\n",
    "params_info = paddle.summary(lenet_SubClass, (1, 1, 28, 28))\n",
    "print(params_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6328582-e1e9-4d7b-b6f4-46059e7cd6f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lenet_SubClass.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975cf26-6930-4002-bc2e-e781c34d3066",
   "metadata": {},
   "source": [
    "## 训练、评估、推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53474af7-4602-4a44-81a1-b51fc5b9c514",
   "metadata": {},
   "source": [
    "我们先介绍利用paddle API快速训练测试，然后再来完整的自定义训练（类似与PyTorch手写数字识别那样）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b778a5-987e-4f03-aedc-275a15eff2ab",
   "metadata": {},
   "source": [
    "指定训练的机器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd38ad-9c91-4b30-94c2-4b256097f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定在 CPU 上训练\n",
    "paddle.device.set_device(\"cpu\")\n",
    "\n",
    "# 指定在 GPU 第 0 号卡上训练\n",
    "# paddle.device.set_device('gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50efda8-757f-4b61-96c4-c8dc25caa4f9",
   "metadata": {},
   "source": [
    "### 使用paddle.Model 高层 API 训练、评估与推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780c73f-7bd5-40dc-afee-0868d7119410",
   "metadata": {},
   "source": [
    "使用 paddle.Model 封装模型<br>使用高层 API 训练模型前，可使用 paddle.Model 将模型封装为一个实例，方便后续进行训练、评估与推理。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc6424-b303-4cb2-8a6e-7237184afad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装模型为一个 Model 实例，便于进行后续的训练、评估和推理\n",
    "model_api = paddle.Model(LeNet())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f2a7a-9e9c-462e-b722-171b99fa717d",
   "metadata": {},
   "source": [
    "使用 Model.prepare 配置训练准备参数\n",
    "\n",
    "用 paddle.Model 完成模型的封装后，需通过 Model.prepare 进行训练前的配置准备工作，包括设置优化算法、Loss 计算方法、评价指标计算方法：\n",
    "\n",
    "- 优化器（optimizer）：即寻找最优解的方法，可计算和更新梯度，并根据梯度更新模型参数。飞桨框架在 paddle.optimizer 下提供了优化器相关 API。并且需要为优化器设置合适的学习率，或者指定合适的学习率策略，飞桨框架在 paddle.optimizer.lr 下提供了学习率策略相关的 API。\n",
    "\n",
    "- 损失函数（loss）：用于评估模型的预测值和真实值的差距，模型训练过程即取得尽可能小的 loss 的过程。飞桨框架在 paddle.nn Loss层 提供了适用不同深度学习任务的损失函数相关 API。\n",
    "\n",
    "- 评价指标（metrics）：用于评估模型的好坏，不同的任务通常有不同的评价指标。飞桨框架在 paddle.metric 下提供了评价指标相关 API。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48767c28-20de-469c-aa15-0606cc612c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为模型训练做准备，设置优化器及其学习率，并将网络的参数传入优化器，设置损失函数和精度计算方式\n",
    "model_api.prepare(\n",
    "    optimizer=paddle.optimizer.Adam(\n",
    "        learning_rate=0.001, parameters=model_api.parameters()\n",
    "    ),\n",
    "    loss=paddle.nn.CrossEntropyLoss(),\n",
    "    metrics=paddle.metric.Accuracy(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56120362-9083-461b-8f0d-25291012af94",
   "metadata": {},
   "source": [
    "使用 Model.fit 训练模型<br>\n",
    "做好模型训练的前期准备工作后，调用 Model.fit 接口来启动训练。 训练过程采用二层循环嵌套方式：内层循环完成整个数据集的一次遍历，采用分批次方式；外层循环根据设置的训练轮次完成数据集的多次遍历。因此需要指定至少三个关键参数：训练数据集，训练轮次和每批次大小:\n",
    "\n",
    "- 训练数据集：传入之前定义好的训练数据集。\n",
    "\n",
    "- 训练轮次（epoch）：训练时遍历数据集的次数，即外循环轮次。\n",
    "\n",
    "- 批次大小（batch_size）：内循环中每个批次的训练样本数。\n",
    "\n",
    "除此之外，还可以设置样本乱序（shuffle）、丢弃不完整的批次样本（drop_last）、同步/异步读取数据（num_workers） 等参数，另外可通过 Callback 参数传入回调函数，在模型训练的各个阶段进行一些自定义操作，比如收集训练过程中的一些数据和参数，详细介绍可参见 自定义 Callback 章节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c47b5f-5b91-47b6-bee9-ca1a6cba4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "model_api.fit(train_loader, epochs=2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d13a15-bf72-46c0-bfb3-449ed9364826",
   "metadata": {},
   "source": [
    "训练好模型后，可在事先定义好的测试数据集上，使用 Model.evaluate 接口完成模型评估操作，结束后根据在 Model.prepare 中定义的 loss 和 metric 计算并返回相关评估结果。\n",
    "\n",
    "返回格式是一个字典:\n",
    "\n",
    "只包含loss， {'loss': xxx}\n",
    "\n",
    "包含loss和一个评估指标， {'loss': xxx, 'metric name': xxx}\n",
    "\n",
    "包含loss和多个评估指标， {'loss': xxx, 'metric name1': xxx, 'metric name2': xxx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5526c632-0638-44f5-9309-b3b100c7bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 evaluate 在测试集上对模型进行验证\n",
    "eval_result = model_api.evaluate(test_dataset, verbose=1)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61887f8-cf3c-43db-9914-fa251846d192",
   "metadata": {},
   "source": [
    "使用 Model.predict 执行推理\n",
    "高层 API 中提供了 Model.predict 接口，可对训练好的模型进行推理验证。只需传入待执行推理验证的样本数据，即可计算并返回推理结果。\n",
    "\n",
    "返回格式是一个列表：\n",
    "\n",
    "模型是单一输出：[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n)]\n",
    "\n",
    "模型是多输出：[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n), (numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n), …]\n",
    "\n",
    "如果模型是单一输出，则输出的形状为 [1, n]，n 表示数据集的样本数。其中每个 numpy_ndarray_n 是对应原始数据经过模型计算后得到的预测结果，类型为 numpy 数组，例如 mnist 分类任务中，每个 numpy_ndarray_n 是长度为 10 的 numpy 数组。\n",
    "\n",
    "如果模型是多输出，则输出的形状为[m, n]，m 表示标签的种类数，在多标签分类任务中，m 会根据标签的数目而定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd012fa-36d1-4ae7-a413-f26ef2cb8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 predict 在测试集上对模型进行推理\n",
    "test_result = model_api.predict(test_dataset)\n",
    "# 由于模型是单一输出，test_result的形状为[1, 10000]，10000是测试数据集的数据量。这里打印第一个数据的结果，这个数组表示每个数字的预测概率\n",
    "print(len(test_result))\n",
    "print(test_result[0][0])\n",
    "\n",
    "# 从测试集中取出一张图片\n",
    "img, label = test_dataset[0]\n",
    "\n",
    "# 打印推理结果，这里的argmax函数用于取出预测值中概率最高的一个的下标，作为预测标签\n",
    "pred_label = test_result[0][0].argmax()\n",
    "print(\"true label: {}, pred label: {}\".format(label[0], pred_label))\n",
    "# 使用matplotlib库，可视化图片\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(img[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3ca37-613f-4558-919c-9445ecb235ef",
   "metadata": {},
   "source": [
    "### paddle自定义训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e29710-b824-43e6-bbf7-41fdca58556e",
   "metadata": {},
   "source": [
    "记录并可视化练过程中的精度、损失变化，测试模型指标等（类似于前面章节的PyTorch手写数字识别）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188f4d6-645d-4374-b3cc-152b9fa278ca",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a4813-8d22-47ef-903c-ea344f900b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import paddle\n",
    "\n",
    "# transform = Normalize(mean=[0.5], std=[0.5], data_format=\"CHW\")\n",
    "# train_dataset = paddle.vision.datasets.MNIST(image_path=train_img, label_path=train_label,mode=\"train\", download=False,transform=transform)\n",
    "# test_dataset = paddle.vision.datasets.MNIST(image_path=test_img, label_path=test_label,mode=\"test\", download=False,transform=transform)\n",
    "# # 用 DataLoader 实现数据加载（前面已经做过了）\n",
    "# train_loader = paddle.io.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
    "# test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "# 实例化模型\n",
    "model_paddle = LeNet()\n",
    "\n",
    "# 设置迭代次数\n",
    "epochs = 3\n",
    "\n",
    "# 设置优化器\n",
    "# optim = paddle.optimizer.SGD(learning_rate=0.01, parameters=model_paddle.parameters(), weight_decay=0.0001)\n",
    "optim = paddle.optimizer.Adam(parameters=model_paddle.parameters(),learning_rate=1e-3)\n",
    "\n",
    "# 设置损失函数\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "test_acc = []\n",
    "test_loss = []\n",
    "\n",
    "model_save = r\"./logs_dir/lenet_paddle\"\n",
    "os.makedirs(model_save, exist_ok=True)\n",
    "model_root = os.path.normpath(os.path.join(os.getcwd(), model_save))\n",
    "\n",
    "best_test_acc = 0.0\n",
    "\n",
    "# 保存断点，用于恢复训练\n",
    "checkpoint = dict()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_correct = 0\n",
    "    epoch_train_samples = 0\n",
    "    \n",
    "    # 训练模式。这只会影响某些模块，如Dropout和BatchNorm。\n",
    "    model_paddle.train()\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        x_data = data[0]  # 训练数据\n",
    "        y_data = data[1]  # 训练标签  [64, 1]\n",
    "        predicts = model_paddle(x_data) # 预测\n",
    "\n",
    "        loss = loss_fn(predicts, y_data)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optim.step()  # 更新参数\n",
    "        optim.clear_grad()  # 清空梯度\n",
    "\n",
    "        epoch_train_loss += loss.numpy()  # 记录训练损失\n",
    "        predicted = paddle.argmax(predicts, axis=1)  # 计算准确率  [64]\n",
    "        epoch_train_correct += paddle.sum(predicted == y_data.reshape([-1])).numpy()\n",
    "        epoch_train_samples += y_data.shape[0]  # += 64\n",
    "\n",
    "    # 记录最后一个train batch的loss到断点\n",
    "    checkpoint['loss'] = loss\n",
    "\n",
    "    # 记录训练精度和损失\n",
    "    train_acc_epoch = epoch_train_correct / epoch_train_samples\n",
    "    train_loss_epoch = epoch_train_loss / len(train_loader) \n",
    "    train_acc.append(train_acc_epoch)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    model_paddle.eval()  # 切换到评估模式\n",
    "    epoch_test_loss = 0  \n",
    "    epoch_test_correct = 0\n",
    "    epoch_test_samples = 0\n",
    "\n",
    "    # 设置为评估模式\n",
    "    model_paddle.eval()  \n",
    "    for batch_id, data in enumerate(test_loader):\n",
    "        x_data = data[0]  # 测试数据\n",
    "        y_data = data[1]  # 测试标签  y_data.shape=[64, 1]\n",
    "        predicts = model_paddle(x_data)  # 预测 predicts.shape=[64, 10]\n",
    "        loss = loss_fn(predicts, y_data)   # 计算损失\n",
    "        epoch_test_loss += loss.numpy()\n",
    "        predicted = paddle.argmax(predicts, axis=1)  # 计算准确率 [64]  \n",
    "        epoch_test_correct += paddle.sum(predicted == y_data.reshape([-1])).numpy()\n",
    "        epoch_test_samples += y_data.shape[0]\n",
    "            \n",
    "    # 记录测试精度和损失\n",
    "    test_acc_epoch = epoch_test_correct / epoch_test_samples\n",
    "    test_loss_epoch = epoch_test_loss / len(test_loader)\n",
    "    test_acc.append(test_acc_epoch)\n",
    "    test_loss.append(test_loss_epoch)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if test_acc_epoch > best_test_acc:\n",
    "        best_test_acc = test_acc_epoch\n",
    "        # 保存Layer参数\n",
    "        paddle.save(model_paddle.state_dict(), os.path.join(model_root, \"model.params\"))\n",
    "        # 保存优化器参数\n",
    "        paddle.save(optim.state_dict(), os.path.join(model_root, \"optim.pdopt\"))\n",
    "        checkpoint['epoch'] = epoch+1\n",
    "        # 保存检查点checkpoint信息\n",
    "        paddle.save(checkpoint, os.path.join(model_root, \"checkpoint.pkl\"))\n",
    "        \n",
    "        print(f\"Saved best model with test accuracy: {test_acc_epoch*100:.2f}%\")\n",
    "        \n",
    "    # 打印训练和测试结果\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "          f\"Train Loss: {train_loss_epoch:.4f}, Train Acc: {train_acc_epoch*100:.2f}%, \"\n",
    "          f\"Test Loss: {test_loss_epoch:.4f}, Test Acc: {test_acc_epoch*100:.2f}%\")\n",
    "\n",
    "# 输出最终训练和测试结果\n",
    "print(\"Training Finished!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131420b-8dbc-4cb2-a4e3-2a9a1c680758",
   "metadata": {},
   "source": [
    "可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e24945-ea13-49ca-a518-7d6cf5bf29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 绘制损失和精度变化曲线\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 损失曲线\n",
    "ax1.plot(range(1, epochs+1), train_loss, label='Train Loss', color='blue')\n",
    "ax1.plot(range(1, epochs+1), test_loss, label='Test Loss', color='red')\n",
    "ax1.set_title('Loss vs Epochs')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# 精度曲线\n",
    "ax2.plot(range(1, epochs+1), train_acc, label='Train Accuracy', color='blue')\n",
    "ax2.plot(range(1, epochs+1), test_acc, label='Test Accuracy', color='red')\n",
    "ax2.set_title('Accuracy vs Epochs')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33845bd0-ac57-4704-86c9-29a24b21e8fd",
   "metadata": {},
   "source": [
    "评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840ef53-49ce-4ebb-9e85-7f0f42e163e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, classification_report\n",
    "from PIL import Image\n",
    "\n",
    "# 实例化模型\n",
    "infer_model = LeNet()\n",
    "\n",
    "# 加载模型\n",
    "infer_model_sd = paddle.load(os.path.join(model_root, \"model.params\"))\n",
    "opt_state_dict = paddle.load(os.path.join(model_root, \"optim.pdopt\"))\n",
    "# （可选）加载断点\n",
    "checkpoint_sd = paddle.load(os.path.join(model_root, \"checkpoint.pkl\"))\n",
    "\n",
    "infer_model.set_state_dict(infer_model_sd)\n",
    "optim.set_state_dict(opt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542579d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试阶段\n",
    "infer_model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "running_test_loss = 0.0\n",
    "test_accuracy_best = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "with paddle.no_grad():\n",
    "    for datas in test_loader:\n",
    "        x_data = datas[0]\n",
    "        y_data = datas[1]\n",
    "        preds = infer_model(x_data)\n",
    "        loss = loss_fn(preds, y_data)\n",
    "        running_test_loss += loss.numpy()\n",
    "        # 计算测试准确率\n",
    "        predicted = paddle.argmax(preds, 1)\n",
    "        # print(f\"{y_data=}\")\n",
    "        total_test += y_data.shape[0]\n",
    "        correct_test += (predicted == y_data.reshape([-1])).sum().item()\n",
    "        # 收集所有标签和预测值，用于计算精确率、召回率和F1分数\n",
    "        all_labels.extend(y_data.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "avg_test_loss = running_test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "# 打印分类报告（精确率、召回率、F1分数）\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "test_losses.append(avg_test_loss)\n",
    "test_accuracies.append(test_accuracy)\n",
    "\n",
    "# 打印当前epoch的训练和测试结果\n",
    "print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bb620-21e4-4fc5-a829-e2eaed7811a3",
   "metadata": {},
   "source": [
    "部署推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1f3e4-8903-4582-83ef-361f8f180210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import paddle \n",
    "img_path = r\"./datasets_/write_mnist/9.png\"\n",
    "color_image = Image.open(img_path).convert('RGB').resize((28,28))\n",
    "# color_image.show()\n",
    "image = Image.open(img_path).convert('L').resize((28,28))  # hw\n",
    "image_np = np.array(image, dtype=float)  # float64\n",
    "image_tensor = paddle.to_tensor(image_np, dtype='float32')  # float32\n",
    "# image_tensor = paddle.cast(image_tensor, dtype='float32')\n",
    "image_tensor = paddle.unsqueeze(image_tensor, 0)  # chw\n",
    "transform = Normalize(mean=[127.5], std=[127.5], data_format=\"CHW\")\n",
    "image_transform = transform(image_tensor)  #  hwc\n",
    "image_tensor = paddle.unsqueeze(image_transform, 0) # nchw\n",
    "\n",
    "infer_model.eval()\n",
    "pred_cls = infer_model(image_tensor)[0].argmax()\n",
    "pred_cls = pred_cls.item()\n",
    "\n",
    "# show()\n",
    "def show_results():\n",
    "    # 创建2个子图：左边是原图，右边是变换后的图\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # 左边展示原图\n",
    "    ax[0].imshow(np.array(color_image))\n",
    "    ax[0].set_title('Original rgb Image')\n",
    "    ax[0].axis('off')  # 关闭坐标轴\n",
    "\n",
    "    # 右边展示变换后的图\n",
    "    ax[1].imshow(paddle.squeeze(image_transform), cmap='gray')\n",
    "    ax[1].set_title(f'Predicted: {pred_cls}')\n",
    "    ax[1].axis('off')  # 关闭坐标轴\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "show_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
