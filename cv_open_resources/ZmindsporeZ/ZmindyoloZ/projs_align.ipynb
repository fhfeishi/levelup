{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mindyolo工程结构  └─   │  ├─ \n",
    "```python\n",
    "~path/to/mindyolo\n",
    "    - /configs    # 配置入口\n",
    "    - /demo        # 推理  ./predict.py\n",
    "    - /deploy      # 部署\n",
    "    - /docs        # 文档、教程\n",
    "    - /examples    # 使用案例(可当作参考)\n",
    "    - /mindyolo    # mindyolo 包\n",
    "    - /requirements\n",
    "    - /tests       # 用于测试， 数据集可视化、loss测试等\n",
    "    - /tutorials   # 配置文件的说明(建议看)、云端应用的教程\n",
    "    - README.md    # 工程介绍，优先看\n",
    "    - requirements.txt setup.py   # 用于配置/构建项目环境\n",
    "    - test.py      # 测试\n",
    "    - train.py     # 训练\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**环境配置**\n",
    "```bash\n",
    "# path/to/mindspore_yolov8\n",
    "cd mindyolo\n",
    "pip install -r requirements.txt\n",
    "pip install -e .   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">介绍一下pip install -e . 和 pip install .\n",
    "\n",
    "`pip install -e .`类似于python setup.py install(传统方法，已经不再推荐，但还是可以用)。\n",
    "-e 或 --editable：可编辑模式（editable mode），表示以开发模式安装包。\n",
    "pip install -e . 会在 Python 解释器的 site-packages 目录中创建一个指向当前项目目录的符号链接（symlink），而不会直接复制代码。这样，修改当前目录的源代码后，无需重新安装，修改会立即生效。\n",
    "pip install -e . 会在 site-packages 目录生成一个 .egg-link 文件，其中记录了当前项目的路径\n",
    "\n",
    "`pip install .`会根据 setup.py 文件中的配置，将当前目录下的包安装到 Python 环境中。这个过程会将包的文件复制到虚拟环境（或系统环境）中的 site-packages 目录。\n",
    "pip install . 会在 site-packages 目录中创建一个 .dist-info 文件夹，其中包含包的元数据（如版本、依赖项等）。\n",
    "与开发模式不同，常规安装会将包的所有文件复制到环境中，而不是创建符号链接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|命令|作用|安装方式|是否创建符号链接|适用场景|\n",
    "|---|---|---|---|---|\n",
    "|pip install .|常规安装|复制到 site-packages|❌ 否|生产环境、正式安装|\n",
    "|python setup.py install|常规安装|复制到 site-packages|❌ 否|传统方法（已不推荐）|\n",
    "|pip install -e .|开发模式安装|通过符号链接连接源码\t|✅ 是|开发调试|\n",
    "|python setup.py develop|开发模式安装|通过符号链接连接源码|✅ 是|传统方法（已不推荐）|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 推荐使用\n",
    "    - 推荐 pip install . 而不是 python setup.py install，因为 pip 处理依赖项和安装流程更完善。\n",
    "    - 推荐 pip install -e . 而不是 python setup.py develop，因为 pip 能正确处理依赖项并兼容 pyproject.toml（现代 Python 项目的标准）。\n",
    "\n",
    "\n",
    "- 如果你在开发一个 Python 包，并希望代码改动后能立即生效，应该使用：\n",
    "    - pip install -e .\n",
    "\n",
    "\n",
    "- 如果你只是想安装并使用包，而不进行修改，应该使用：\n",
    "    - pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集格式的转换\n",
    "\n",
    "```python\n",
    "# my voc-ObjecDetection-dataset structure\n",
    "VOC_2007:\n",
    "~/paddle_yolov8/dataset/VOCDevkit/VOC2007\n",
    "    - /Annotations   # *.xml\n",
    "    - /ImageSets\n",
    "        - /Main      # *.txt(划分的数据集.txt)  txt内每一行都是无后缀的数据文件名\n",
    "    - /JPEGImages    # *.jpg\n",
    "\n",
    "# target voc-ObjecDetection-dataset structure\n",
    "mdspo_voc:\n",
    "~/path/to/dataset/mdspo_voc\n",
    "    - /VOCDevkit/VOC2007  # my dataset\n",
    "        - /Annotations  # *.xml   \n",
    "        - /ImageSets\n",
    "            - /Main     # *.txt    \n",
    "        - /JPEGImages   # *.jpg\n",
    "    \n",
    "    - /labels  # line:cls_id normed_x normed_y normed_w normed_h/n\n",
    "        - /train        # *.txt \n",
    "        - /val          # *.txt \n",
    "        - /test         # *.txt\n",
    "    - /images\n",
    "        - /train        # *.jpg\n",
    "        - /val          # *.jpg \n",
    "        - /test         # *.jpg\n",
    "    - train.txt  # path/to/*.jpg\n",
    "    - val.txt    # path/to/*.jpg\n",
    "    - test.txt   # path/to/*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['head', 'helmet', 'safetybelt']\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "\n",
    "# 获取类别的列表  ['head' 'helmet' sfatebelt], 用于获取cls_id\n",
    "def get_myclasses(clsfile='my_classes.txt'):\n",
    "    with open(clsfile, \"r\", encoding='utf-8') as file:\n",
    "        cls_list = file.readlines()\n",
    "        return [c.strip() for c in cls_list]\n",
    "\n",
    "my_classes = get_myclasses()\n",
    "print(my_classes)  # ['head', 'helmet', 'safetybelt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_annotations(lbl_filepath, img_data_dir, label_file):\n",
    "    img_filename = os.path.basename(lbl_filepath).replace('.xml', '.jpg')\n",
    "    tem_ = Image.open(os.path.join(img_data_dir, img_filename)).convert('RGB')\n",
    "    w, h = tem_.size\n",
    "    in_file = open(lbl_filepath, \"r\", encoding='utf-8')\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = 0 \n",
    "        if obj.find('difficult')!=None:\n",
    "            difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in my_classes or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = my_classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(float(xmlbox.find('xmin').text)), \n",
    "             int(float(xmlbox.find('ymin').text)), \n",
    "             int(float(xmlbox.find('xmax').text)), \n",
    "             int(float(xmlbox.find('ymax').text)))\n",
    "        x_normed = (b[0]+b[2]) /2 /w\n",
    "        y_normed = (b[1]+b[3]) /2 /h\n",
    "        w_normed = abs(b[0]-b[2]) /w\n",
    "        h_normed = abs(b[1]-b[3]) /h\n",
    "        # label_file.write(\" \".join([str(a) for a in b]) + ' ' + str(cls_id))\n",
    "        label_file.write(f\"{cls_id} {x_normed} {y_normed} {w_normed} {h_normed}\\n\")\n",
    "        \n",
    "    \n",
    "def copy_files(src_root='dataset/VOCdevkit/VOC2007', \n",
    "               tgt_root=\"mindyolo/dataset/mdspo_voc\",\n",
    "               mode = 'train'):\n",
    "    os.makedirs(tgt_root, exist_ok=True)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        data_type = 'train'\n",
    "    elif mode == 'val':\n",
    "        data_type = 'val'\n",
    "    else:\n",
    "        data_type = 'test'\n",
    "            \n",
    "    # src\n",
    "    src_img_dir = os.path.join(src_root, \"JPEGImages\")\n",
    "    src_log_path = os.path.join(src_root, f\"ImageSets/Main/{data_type}.txt\")\n",
    "    src_lbl_dir = os.path.join(src_root, \"Annotations\")    \n",
    "    \n",
    "    # read data name\n",
    "    def get_dataNames(logTxt=src_log_path):\n",
    "        with open(logTxt, \"r\", encoding='utf-8') as f:\n",
    "                fnames = f.readlines()\n",
    "        return fnames\n",
    "    data_names = get_dataNames()\n",
    "    \n",
    "    # # get train.txt  val.txt  test.txt\n",
    "    # with open(f\"{tgt_root}/{data_type}.txt\", \"w\", encoding='utf-8') as fi:\n",
    "    #     for li in data_names:\n",
    "    #         li = li.strip()\n",
    "    #         fi.write(f\"../dataset/mdspo_voc/images/{li}\\n\")\n",
    "    \n",
    "    # target img dir\n",
    "    tgt_img_dir = os.path.join(tgt_root, f\"images/{data_type}\")\n",
    "    os.makedirs(tgt_img_dir, exist_ok=True)\n",
    "    # # copy images\n",
    "    def copy_imgs(dir1, dir2, fnames):\n",
    "        for fname in fnames:\n",
    "            fname = fname.strip()\n",
    "            src_img_path = os.path.join(dir1, f\"{fname}.jpg\")\n",
    "            if os.path.isfile(src_img_path):\n",
    "                tgt_imag_path = os.path.join(dir2, f\"{fname}.jpg\")\n",
    "                shutil.copyfile(src_img_path, tgt_imag_path)\n",
    "            else:\n",
    "                print(f\"{fname}.jpg file is not file\")\n",
    "                print(f\"{src_img_path=}\")\n",
    "                print(\"------------------------------------------------------\")  \n",
    "    copy_imgs(dir1=src_img_dir, dir2=tgt_img_dir, fnames=data_names)  \n",
    "    \n",
    "    # target lbl dir\n",
    "    tgt_lbl_dir = os.path.join(tgt_root, f\"labels/{data_type}\")\n",
    "    os.makedirs(tgt_lbl_dir, exist_ok=True)\n",
    "    for name_ in data_names:\n",
    "        xml=name_.strip()\n",
    "        tgt_lbl_path = os.path.join(tgt_lbl_dir, f\"{xml}.txt\")\n",
    "        fil = open(tgt_lbl_path, \"w\", encoding='utf-8')\n",
    "        src_xml_path = os.path.join(src_lbl_dir, f\"{xml}.xml\")\n",
    "        if os.path.isfile(src_xml_path):\n",
    "            convert_annotations(src_xml_path, src_img_dir, fil)\n",
    "        else:\n",
    "            print(f\"{xml}.jpg file is not file\")\n",
    "            print(f\"{src_xml_path=}\")\n",
    "            print(\"------------------------------------------------------\")        \n",
    "        fil.close()\n",
    "    \n",
    "copy_files(mode='train')\n",
    "copy_files(mode='val')   \n",
    "copy_files(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  数据名得是数字  0001 0002  \n",
    "\n",
    "def get_num_fname(data_dir=\"mindyolo/dataset/mdspo_voc\", mode=\"train\"):\n",
    "    if mode == \"train\":\n",
    "        data_t = \"train\"\n",
    "    elif mode == \"val\":\n",
    "        data_t = \"val\"\n",
    "    else:\n",
    "        data_t = \"test\"\n",
    "        \n",
    "    img_d = os.path.join(data_dir, f\"images/{data_t}\")\n",
    "    lbl_d = os.path.join(data_dir, f\"labels/{data_t}\")\n",
    "\n",
    "    ims = {name.split('.')[0] for name in os.listdir(img_d) if name.endswith('.jpg')}\n",
    "    lbs = {name.split('.')[0] for name in os.listdir(lbl_d) if name.endswith('.txt')}\n",
    "    \n",
    "    # get train.txt  val.txt  test.txt\n",
    "    fe = open(os.path.join(\"mindyolo/dataset/mdspo_voc\", data_t+\".txt\"), \"w\", encoding='utf-8')\n",
    "    if ims - lbs == set():\n",
    "        start_num = 1\n",
    "        for i, na in enumerate(ims, start=start_num):\n",
    "            fe.write(f\"./images/{data_t}/{na}.jpg\\n\")\n",
    "            # new_name = f\"{i:06d}\"\n",
    "            # fe.write(f\"../../dataset/images/{new_name}.jpg\\n\")\n",
    "            # src_img = os.path.join(img_d, f\"{na}.jpg\")        \n",
    "            # dst_img = os.path.join(img_d, f\"{new_name}.jpg\")\n",
    "            # os.rename(src_img, dst_img)\n",
    "            # src_lbl = os.path.join(lbl_d, f\"{na}.txt\")\n",
    "            # dst_lbl = os.path.join(lbl_d, f\"{new_name}.txt\")\n",
    "            # os.rename(src_lbl, dst_lbl)\n",
    "        fe.close()\n",
    "    else:\n",
    "        print(f\"{ims-lbs=}\")\n",
    "get_num_fname(mode='train')\n",
    "get_num_fname(mode='val')\n",
    "get_num_fname(mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练配置文件 configs/mdspo_voc.yaml\n",
    "```yaml\n",
    "\n",
    "data:\n",
    "  dataset_name: mdspo_voc\n",
    "\n",
    "  train_set: dataset/mdspo_voc/train.txt  \n",
    "  val_set: dataset/mdspo_voc/val.txt  \n",
    "  test_set: dataset/mdspo_voc/test.txt  \n",
    "  \n",
    "  nc: 3\n",
    "\n",
    "  # class names\n",
    "  names: [ 'head', 'helmet', 'safetybelt' ]\n",
    "\n",
    "  train_transforms: []\n",
    "  test_transforms: []\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主配置文件 configs/yolov8/yolov8s_main.py\n",
    "\n",
    "```yaml\n",
    "__BASE__: [\n",
    "  '../mdspo_voc.yaml',   # 数据集配置\n",
    "  './hyp.scratch.low.yaml',  # 优化器、损失、数据读取、数据增强low 配置\n",
    "  './yolov8-base.yaml'  # 模型配置，sync_gn等\n",
    "]\n",
    "\n",
    "# weights= ./preweights/yolov8-s_500e_mAP446-3086f0c9.ckpt\n",
    "\n",
    "overflow_still_update: False\n",
    "network:\n",
    "  depth_multiple: 0.33  # scales module repeats\n",
    "  width_multiple: 0.50  # scales convolution channels\n",
    "  max_channels: 1024\n",
    "\n",
    "# 源文件位置\n",
    "data:\n",
    "  num_parallel_workers: 8  # 如果报错windwos不支持python多线程就设为1\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成dataset/mdspo_voc/annotations/instances_val2017.json文件用于测试，这里是直接调用的pycocotools的api，所以需要我们将数据整理成api要求的格式，直接修改这个脚本就可以mindspore_yolov8\\mindyolo\\examples\\finetune_car_detection\\crejson.py 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# 设置数据集路径\n",
    "dataset_path = \"dataset/mdspo_voc\"\n",
    "images_path = os.path.join(dataset_path, \"images/test\")\n",
    "labels_path = os.path.join(dataset_path, \"labels/test\")\n",
    "\n",
    "# 类别映射\n",
    "categories = [\n",
    "{\"id\": 0, \"name\": \"head\"},\n",
    "{\"id\": 1, \"name\": \"helmet\"},\n",
    "{\"id\": 2, \"name\": \"safetybelt\"},\n",
    "    # 添加更多类别\n",
    "]\n",
    "\n",
    "\n",
    "# YOLO格式转COCO格式的函数\n",
    "def convert_yolo_to_coco(x_center, y_center, width, height, img_width, img_height):\n",
    "    x_min = (x_center - width / 2) * img_width\n",
    "    y_min = (y_center - height / 2) * img_height\n",
    "    width = width * img_width\n",
    "    height = height * img_height\n",
    "    return [x_min, y_min, width, height]\n",
    "\n",
    "\n",
    "# 初始化COCO数据结构\n",
    "def init_coco_format():\n",
    "    return {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "\n",
    "# 处理每个数据集分区\n",
    "split=''\n",
    "coco_format = init_coco_format()\n",
    "annotation_id = 1\n",
    "imgs_list = os.listdir(os.path.join(images_path, split))\n",
    "imgs_list.sort()\n",
    "for img_name in imgs_list:\n",
    "    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(images_path, split, img_name)\n",
    "        label_path = os.path.join(labels_path, split, img_name.replace(\"jpg\", \"txt\"))\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size\n",
    "        image_info = {\n",
    "            \"file_name\": img_name,\n",
    "            \"id\": len(coco_format[\"images\"]) + 1,\n",
    "            \"width\": img_width,\n",
    "            \"height\": img_height\n",
    "        }\n",
    "        coco_format[\"images\"].append(image_info)\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as file:\n",
    "                for line in file:\n",
    "                    category_id, x_center, y_center, width, height = map(float, line.split())\n",
    "                    bbox = convert_yolo_to_coco(x_center, y_center, width, height, img_width, img_height)\n",
    "                    annotation = {\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": image_info[\"id\"],\n",
    "                        \"category_id\": int(category_id) ,\n",
    "                        \"bbox\": bbox,\n",
    "                        \"area\": bbox[2] * bbox[3],\n",
    "                        \"iscrowd\": 0\n",
    "                    }\n",
    "                    coco_format[\"annotations\"].append(annotation)\n",
    "                    annotation_id += 1\n",
    "\n",
    "# 为每个分区保存JSON文件\n",
    "testdir = r\"dataset/mdspo_voc/annotations\"\n",
    "os.makedirs(testdir,exist_ok=True)\n",
    "with open(f\"{testdir}/instances_val2017.json\", \"w\") as json_file:\n",
    "    json.dump(coco_format, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型配置 configs/yolov8-base \n",
    "```yaml\n",
    "\n",
    "epochs: 500  # total train epochs\n",
    "per_batch_size: 4\n",
    "img_size: 640\n",
    "iou_thres: 0.7\n",
    "conf_free: True\n",
    "sync_bn: False    # ddp True\n",
    "anchor_base: False\n",
    "opencv_threads_num: 0  # opencv: disable threading optimizations\n",
    "\n",
    "network:\n",
    "  model_name: yolov8\n",
    "  nc: 80  # number of classes\n",
    "  reg_max: 16\n",
    "\n",
    "  stride: [8, 16, 32]\n",
    "\n",
    "  # YOLOv8.0n backbone\n",
    "  backbone:\n",
    "    # [from, repeats, module, args]\n",
    "    - [-1, 1, ConvNormAct, [64, 3, 2]]  # 0-P1/2\n",
    "    - [-1, 1, ConvNormAct, [128, 3, 2]]  # 1-P2/4\n",
    "    - [-1, 3, C2f, [128, True]]\n",
    "    - [-1, 1, ConvNormAct, [256, 3, 2]]  # 3-P3/8\n",
    "    - [-1, 6, C2f, [256, True]]\n",
    "    - [-1, 1, ConvNormAct, [512, 3, 2]]  # 5-P4/16\n",
    "    - [-1, 6, C2f, [512, True]]\n",
    "    - [-1, 1, ConvNormAct, [1024, 3, 2]]  # 7-P5/32\n",
    "    - [-1, 3, C2f, [1024, True]]\n",
    "    - [-1, 1, SPPF, [1024, 5]]  # 9\n",
    "\n",
    "  # YOLOv8.0n head\n",
    "  head:\n",
    "    - [-1, 1, Upsample, [None, 2, 'nearest']]\n",
    "    - [[-1, 6], 1, Concat, [1]]  # cat backbone P4\n",
    "    - [-1, 3, C2f, [512]]  # 12\n",
    "\n",
    "    - [-1, 1, Upsample, [None, 2, 'nearest']]\n",
    "    - [[-1, 4], 1, Concat, [1] ]  # cat backbone P3\n",
    "    - [-1, 3, C2f, [256]]  # 15 (P3/8-small)\n",
    "\n",
    "    - [-1, 1, ConvNormAct, [256, 3, 2]]\n",
    "    - [[ -1, 12], 1, Concat, [1]]  # cat head P4\n",
    "    - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)\n",
    "\n",
    "    - [-1, 1, ConvNormAct, [512, 3, 2]]\n",
    "    - [[-1, 9], 1, Concat, [1]]  # cat head P5\n",
    "    - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)\n",
    "\n",
    "    - [[15, 18, 21], 1, YOLOv8Head, [nc, reg_max, stride]]  # Detect(P3, P4, P5)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**train**\n",
    "```bash\n",
    "python train.py --config ./configs/yolov8/yolov8s_main.yaml --device_target CPU\n",
    "```\n",
    "\n",
    "**infer**\n",
    "```bash\n",
    "python demo/predict.py --config ./configs/yolov8/yolov8s_main.yaml --weight /path_to_ckpt/WEIGHT.ckpt --image_path /path/to/img --device_target CPU\n",
    "```\n",
    "\n",
    "**test**\n",
    "```bash\n",
    "python test.py --config ./configs/yolov8/yolov8s_main.yaml --weight /path_to_ckpt/WEIGHT.ckpt --device_target CPU\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "data:\n",
    "  num_parallel_workers: 8  # 如果报错windwos不支持python多线程就设为1\n",
    "\n",
    "  # multi-stage data augment\n",
    "  train_transforms: {\n",
    "    stage_epochs: [ 490, 10 ],\n",
    "    trans_list: [\n",
    "      [\n",
    "        { func_name: mosaic, prob: 1.0 },\n",
    "        { func_name: resample_segments },\n",
    "        { func_name: random_perspective, prob: 1.0, degrees: 0.0, translate: 0.1, scale: 0.5, shear: 0.0 },\n",
    "        # {func_name: albumentations},\n",
    "        {func_name: hsv_augment, prob: 1.0, hgain: 0.015, sgain: 0.7, vgain: 0.4},\n",
    "        {func_name: fliplr, prob: 0.5},\n",
    "        {func_name: label_norm, xyxy2xywh_: True},\n",
    "        {func_name: label_pad, padding_size: 160, padding_value: -1},\n",
    "        {func_name: image_norm, scale: 255.},\n",
    "        {func_name: image_transpose, bgr2rgb: True, hwc2chw: True}\n",
    "      ],\n",
    "      [\n",
    "        {func_name: letterbox, scaleup: True},\n",
    "        {func_name: resample_segments},\n",
    "        {func_name: random_perspective, prob: 1.0, degrees: 0.0, translate: 0.1, scale: 0.5, shear: 0.0},\n",
    "        # {func_name: albumentations},\n",
    "        {func_name: hsv_augment, prob: 1.0, hgain: 0.015, sgain: 0.7, vgain: 0.4},\n",
    "        {func_name: fliplr, prob: 0.5},\n",
    "        {func_name: label_norm, xyxy2xywh_: True},\n",
    "        {func_name: label_pad, padding_size: 160, padding_value: -1},\n",
    "        {func_name: image_norm, scale: 255.},\n",
    "        {func_name: image_transpose, bgr2rgb: True, hwc2chw: True}\n",
    "      ]]\n",
    "  }\n",
    "\n",
    "  test_transforms: [\n",
    "    {func_name: letterbox, scaleup: False, only_image: True},\n",
    "    {func_name: image_norm, scale: 255.},\n",
    "    {func_name: image_transpose, bgr2rgb: True, hwc2chw: True}\n",
    "  ]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdspo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
